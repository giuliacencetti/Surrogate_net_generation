{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deffuant model. Save only nb of groups, groups size and convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import random\n",
    "from itertools import groupby\n",
    "from random import shuffle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "from topological_metrics import get_weighted_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pr_school\";gap = 300;state_gap = 1200;nb_states_L = 3;nb_states_e = 8\n",
    "#dataset = \"h_school11\";gap = 1200;state_gap = 1200;nb_states_L = 3;nb_states_e = 7\n",
    "#dataset = \"h_school13\";gap = 1200;state_gap = 1200;nb_states_L = 4;nb_states_e = 29\n",
    "#dataset = \"InVS15\"; gap = 3600; state_gap = 3600; nb_states_L = 3;nb_states_e = 12\n",
    "#dataset = \"hypertext\";gap = 1200;state_gap = 1200;nb_states_L = 3;nb_states_e = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pr_school'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_edgelist_D(dataset,gap):\n",
    "\n",
    "    edgelist = pd.read_csv(\"../../Datasets/\"+dataset+\".dat\",sep=\" \",names=[\"t\",\"i\",\"j\"])\n",
    "    nb_nodes = max(max(edgelist.i),max(edgelist.j)) + 1\n",
    "    nodes_list = np.arange(0,nb_nodes)\n",
    "    times = [int(x/gap) for x in edgelist.t]\n",
    "    edgelist.t = times\n",
    "\n",
    "    return nodes_list,edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_edgelist_surrogate(dataset,net,net_idx,nb_states_e,gap,nb_states_L):\n",
    "    path = '../../Generated_graphs/d2/'\n",
    "    if net == 'E':\n",
    "        directory = path+\"%s_E_gap_%d_%d_states_e/\"%(dataset,gap,nb_states_e)\n",
    "        edgelist = pd.read_csv(directory+\"/%d.dat\"%net_idx,sep=\" \",names=[\"t\",\"i\",\"j\"])\n",
    "\n",
    "    elif net == 'ES':       \n",
    "        directory = path+\"%s_ES_gap_%d_%d_states_e_%d_states_L/\"%(dataset,gap,nb_states_e,nb_states_L)\n",
    "        edgelist = pd.read_csv(directory+\"/%d.dat\"%net_idx,sep=\" \",names=[\"t\",\"i\",\"j\"])\n",
    "\n",
    "    elif net == 'EST':       \n",
    "        directory = path+\"%s_EST_gap_%d_%d_states_e_%d_states_L/\"%(dataset,gap,nb_states_e,nb_states_L)\n",
    "        edgelist = pd.read_csv(directory+\"/%d.dat\"%net_idx,sep=\" \",names=[\"t\",\"i\",\"j\"])\n",
    "    \n",
    "    nb_nodes = max(max(edgelist.i),max(edgelist.j)) + 1\n",
    "    nodes_list = np.arange(0,nb_nodes)\n",
    "    times = [int(x/gap) for x in edgelist.t]\n",
    "    edgelist.t = times\n",
    "\n",
    "    return nodes_list,edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_edgelist_dict(data_):\n",
    "    edgelist_dict = {}\n",
    "    for t in range(max(data_.t) + 1):\n",
    "        edgelist_dict[t] = []\n",
    "    \n",
    "    for _, row in data_.iterrows():\n",
    "        if row['t'] in edgelist_dict:\n",
    "            if [row['i'],row['j']] not in edgelist_dict[row['t']]:\n",
    "                edgelist_dict[row['t']].append([row['i'],row['j']])\n",
    "            if [row['j'],row['i']] in edgelist_dict[row['t']] and row['i'] != row['j']:\n",
    "                print('error1')\n",
    "        else:\n",
    "            print('error2')\n",
    "    return edgelist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(q, t0, edgelist_t,Gw,time_ev_name):\n",
    "    b_max = max(edgelist_t.keys())\n",
    "    b = 0\n",
    "    t_interval_save = 5\n",
    "    #Initialize time 0\n",
    "    x = list(np.random.uniform(low=0, high=1, size=len(nodes_list)))\n",
    "    t = t0\n",
    "    t_conv = 0\n",
    "    for times in range(100000):\n",
    "        old_x = x.copy()\n",
    "        shuffle(edgelist_t[t])\n",
    "        for edge in edgelist_t[t]:\n",
    "            \n",
    "            if np.abs(x[edge[0]] - x[edge[1]]) < q:\n",
    "                mid_x = (x[edge[0]] + x[edge[1]])/2\n",
    "                x[edge[0]] = mid_x\n",
    "                x[edge[1]] = mid_x\n",
    "                \n",
    "        if time_ev_name != None:\n",
    "                save_on_csv(time_ev_name,x,'a')\n",
    "                \n",
    "        if not t_conv%t_interval_save:\n",
    "            \n",
    "            flag = False\n",
    "            for edge in Gw.edges():\n",
    "                xdiff = np.abs(x[edge[0]] - x[edge[1]])\n",
    "                if xdiff < q and xdiff > 0.001:\n",
    "                    flag = True\n",
    "            if flag == False:\n",
    "                break\n",
    "            \n",
    "        t += 1\n",
    "        if t > max(edgelist_t.keys()):\n",
    "            t = 0  \n",
    "        t_conv += 1\n",
    "\n",
    "    return x, t_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_equal(iterable):\n",
    "    g = groupby(iterable)\n",
    "    return next(g, True) and not next(g, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose if save also time evolution or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_time_ev = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_time_ev:\n",
    "    q_range = [0.1, 0.2, 0.3, 0.4]\n",
    "else:\n",
    "    q_range = np.linspace(0.1,0.55,num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'results/' # to save results\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_surr = 10 # nb of generated networks\n",
    "if save_time_ev:\n",
    "    nb_runs_surr = 1\n",
    "else:\n",
    "    nb_runs_surr = 20 # nb of simulations on each network (so 200 simulations in total)\n",
    "nb_runs_D = nb_surr*nb_runs_surr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q 0.1\n",
      "q 0.2\n",
      "q 0.3\n",
      "q 0.4\n"
     ]
    }
   ],
   "source": [
    "net = 'D'\n",
    "\n",
    "# Load edgelist\n",
    "nodes_list,edgelist = upload_edgelist_D(dataset,gap)\n",
    "Gw = get_weighted_graph(build_graphs(edgelist,gap))\n",
    "edgelist_dict = obtain_edgelist_dict(edgelist)\n",
    "non_empty_t = np.unique(edgelist.t)\n",
    "\n",
    "\n",
    "\n",
    "# Simulate\n",
    "for q in q_range:\n",
    "    print('q',q)\n",
    "    # save also time evolution or not:\n",
    "    if save_time_ev:\n",
    "        time_ev_name = \"results/time_evol_t_save_1/x_t_%s_%s_q_%.2f.csv\"%(dataset,net,q)\n",
    "    else:\n",
    "        time_ev_name = None\n",
    "    \n",
    "    filename_x = \"results/xf_%s_%s_q_%.2f.csv\"%(dataset,net,q) # opinions\n",
    "    filename_t = \"results/t_conv_%s_%s_q_%.2f.txt\"%(dataset,net,q) # converegence time\n",
    "    file_t = open(filename_t, 'a+')\n",
    "    for run in range(nb_runs_D):\n",
    "        t0 = random.choice(non_empty_t)\n",
    "        x, t_conv = simulate(q, t0, edgelist_dict,Gw,time_ev_name)\n",
    "        save_on_csv(filename_x,x,'a')\n",
    "        file_t.write('%d\\n'%t_conv)\n",
    "    file_t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b251ff7fb948a98240f3bdf4dac1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_idx 0\n",
      "net_idx 1\n",
      "net_idx 2\n",
      "net_idx 3\n",
      "net_idx 4\n",
      "net_idx 5\n",
      "net_idx 6\n",
      "net_idx 7\n",
      "net_idx 8\n",
      "net_idx 9\n",
      "ES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b60de680287476090fffccd5d0965cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_idx 0\n",
      "net_idx 1\n",
      "net_idx 2\n",
      "net_idx 3\n",
      "net_idx 4\n",
      "net_idx 5\n",
      "net_idx 6\n",
      "net_idx 7\n",
      "net_idx 8\n",
      "net_idx 9\n",
      "EST\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18ba725c5134ef8914ecddf84ba083b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_idx 0\n",
      "net_idx 1\n",
      "net_idx 2\n",
      "net_idx 3\n",
      "net_idx 4\n",
      "net_idx 5\n",
      "net_idx 6\n",
      "net_idx 7\n",
      "net_idx 8\n",
      "net_idx 9\n"
     ]
    }
   ],
   "source": [
    "for net in ['E','ES','EST']:\n",
    "    print(net)\n",
    "    for net_idx in tqdm(range(nb_surr)):\n",
    "        print('net_idx',net_idx)\n",
    "        # Load edgelist   \n",
    "        nodes_list,edgelist = upload_edgelist_surrogate(dataset,net,net_idx,nb_states_e,gap,nb_states_L)\n",
    "        Gw = get_weighted_graph(build_graphs(edgelist,gap))\n",
    "        edgelist_dict = obtain_edgelist_dict(edgelist)\n",
    "\n",
    "        non_empty_t = np.unique(edgelist.t)\n",
    "        \n",
    "        # Simulate\n",
    "        for q in q_range:\n",
    "            # save also time evolution or not:\n",
    "            if save_time_ev:\n",
    "                time_ev_name = \"results/time_evol_t_save_1/x_t_%s_%s_q_%.2f.csv\"%(dataset,net,q)\n",
    "            else:\n",
    "                time_ev_name = None\n",
    "                \n",
    "            filename_x = \"results/xf_%s_%s_q_%.2f_%d.csv\"%(dataset,net,q,net_idx) # opinions\n",
    "            filename_t = \"results/t_conv_%s_%s_q_%.2f.txt\"%(dataset,net,q) # converegence time\n",
    "            file_t = open(filename_t, 'a+')\n",
    "            for run in range(nb_runs_surr):\n",
    "                t0 = random.choice(non_empty_t)\n",
    "                x, t_conv = simulate(q, t0, edgelist_dict,Gw,time_ev_name)\n",
    "                save_on_csv(filename_x,x,'a')\n",
    "                file_t.write('%d\\n'%t_conv)\n",
    "            file_t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
